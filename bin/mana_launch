#!/bin/sh

# FIXME: USER FORGOT TO USE srun (detect and report error?):
# [40000] NOTE at socketconnlist.cpp:218 in scanForPreExisting; REASON='found pre-existing socket... will not be restored'
# fd = 3
# device = socket:[1350385918]
# [Sat Apr 10 09:03:13 2021] [unknown] Fatal error in MPI_Init: Other MPI error, error stack:
# MPIR_Init_thread(537):
# MPID_Init(246).......: channel initialization failed
# MPID_Init(647).......:  PMI2 init failed: 1
# bin/mana_launch: line 48: 15391 Aborted
# $dir/dmtcp_launch $options -h $host --no-gzip --join --disable-dl-plugin --with-plugin $PWD/lib/dmtcp/libmana.so "$target_app"

# FIXME: USER FORGOT TO USE srun and there is no salloc (detect and report error?):
# + bin/dmtcp_launch 10 -i --mpi -h cori03 --no-gzip --join --disable-dl-plugin --with-plugin /global/homes/g/gdc0/mana-rohgarg-orig/lib/dmtcp/libmana.so contrib/mpi-proxy-split/test/ping_pong.mana.exe
# *** ERROR:Executable to run w/ DMTCP appears not to be readable,
# ***or no such executable in path.

dir=`dirname $0`

if [ -z "$1" ]; then
  echo "USAGE:  $0 [--verbose] [DMTCP_OPTIONS ...] [--ckptdir DIR]" \\
  echo "                                                       MANA_EXECUTABLE"
  echo "        For DMTCP options, do: $0 --help"
  echo "  NOTE: MANA_EXECUTABLE must be compiled with libmpistub.so"
  echo "        See $dir/../contrib/mpi-proxy-split/test/ for examples."
  exit 1
fi

options=""
target_app=""
help=0
verbose=0
srun_sbatch_found=0
while [ -n "$1" ]; do
  if [ "$1" == --verbose ]; then
    verbose=1
  elif [ "$1" == --help ]; then
    help=1
  elif [ "$1" == srun ] || [ "$1" == sbatch ]; then
    srun_sbatch_found=1
  elif [ "$1" == --ckptdir ]; then
    if [ ! -d "$2" ]; then
      echo "$0: --ckptdir $2: Checkpoint directory doesn't exist"
      exit 9
    fi
    options="$options $1 $2"
    shift
  else
    if [ "$1" == --quiet ] || [ "$!" == "-q" ]; then
      export MANA_QUIET=1
      # And --quiet is also a flag for DMTCP. Continue from here.
    fi
    # other flags, options, and target_app executable
    options="$options $1"
    # The last word will be the target_app.
    target_app="$1"
  fi
  shift
done

if [ "$help" -eq 1 ]; then
  $dir/dmtcp_launch --help $options
  exit 0
fi

SITE=unknown
if [ "$NERSC_HOST" = "cori" ]; then
  SITE=nersc
elif [ "$NERSC_HOST" = "gerty" ]; then
  SITE=nersc
elif [ "$NERSC_HOST" = "perlmutter" ]; then
  SITE=nersc
fi

if [ "$SITE" = "nersc" ]; then
  if [ -z "$SLURM_JOB_ID" ]; then
    echo "SLURM_JOB_ID env variable not set; No salloc/sbatch jobs running?"
    exit 2
  fi

  if [ "$srun_sbatch_found" -eq 1 ]; then
    echo ""
    echo "  *** Usage: srun/sbatch ... mana_launch ... MPI_EXECUTABLE ..."
    echo ""
    exit 3
  fi
else
  if [ -z "$MPI_LOCALNRANKS" ]; then
    echo "MPI_LOCALNRANKS env variable not set; No 'mpirun -np XX' used?"
  fi
fi

if ls -d ckpt_rank_* 2>/dev/null 1>&2; then
  echo 'Checkpoint files already in current directory:  ls -d ckpt_rank_*'
  echo 'Please move or delete previous checkpoint before running "mana_launch"'
  exit 4
fi

if [ ! -z "$SLURM_JOB_ID" ]; then
  MANA_RC=$HOME/.mana-slurm-$SLURM_JOB_ID.rc
else
  MANA_RC=$HOME/.mana.rc
fi

host=`hostname`
submissionHost=`grep Host: $MANA_RC | sed -e 's%Host: %%'|sed -e 's% .*$%%'`
submissionPort=`grep Port: $MANA_RC | sed -e 's%Port: %%'|sed -e 's% .*$%%'`

coordinator_found=0
$dir/dmtcp_command -s -h $submissionHost -p $submissionPort 1>/dev/null \
                                                     && coordinator_found=1
if [ "$coordinator_found" == 0 ]; then
  echo "*** Checking for coordinator:"
  set -x
    # `dirname $0`/dmtcp_command -s -h `hostname`
    $dir/dmtcp_command --status --coord-host $submissionHost \
                                --coord-port $submissionPort
  set +x
  echo "  No coordinator detected.   Try:"
  echo "    $dir/mana_coordinator"
  echo "  Or:"
  echo "    $dir/dmtcp_coordinator --exit-on-last -q --daemon"
  exit 5
fi

# At higher ranks, restarting NIMROD causes a heap overflow (for a more detailed
# write up, refer to Section 4 of mpi-proxy-split/doc/nimrod-build-tutorial.txt).
# A temporary workaround is to swap the memory addresses of NIMROD and lh_proxy,
# which requires a specially built version of lh_proxy.
if echo $target_app | grep -q nimrod ; then
  export USE_LH_PROXY_DEFADDR=1
fi

if [ "$verbose" == 0 ]; then
  options="-q -q $options"
fi

libdir="`dirname $0`/../lib/dmtcp"

if [ -z "$SLURM_JOB_ID" ]; then
  echo ""
  echo "*******************************************************"***
  echo "* Launching MANA job.  If using more than one rank, do:  *"
  echo "*   'srun ... mana_launch ... MPI_TARGET ...', or sbatch *"
  echo "*******************************************************"***
  echo ""
fi

if [ "$SITE" = "nersc" ]; then
  if [ -z "$SLURM_NTASKS" ]; then
    echo ""
    echo "*******************************************************"
    echo "* SLURM_NTASKS env. var. not detected.                *"
    echo "* Did you forget to run mana_launch with srun/sbatch? *"
    echo "*******************************************************"
    echo ""
  fi
### OBSOLETE:  UPDATE OR DELETE:
## elif [ -z "$MPI_LOCALNRANKS" ]; then
##   echo ""
##   echo "**********************************************************"
##   echo "* MPI_LOCALNRANKS env. var. not detected.                *"
##   echo "* Did you forget to run mana_restart with mpirun -np XX? *"
##   echo "**********************************************************"
##   echo ""
fi

# Set a dummy SLURM_JOB_ID when MANA is not launched under Slurm. It is to
# prevent DMTCP from misidentifyin shared FDs created by mpirun as pre-existing
# FDs during launch. Please see the detailed comment in the `scanForPreExisting`
# function in socketconnlist.cpp.
#
# FIXME: This is a temporary workaround and will be removed after the issue is
#        fixed in DMTCP.
if [ -z "$SLURM_JOB_ID" ]; then
  export SLURM_JOB_ID=1
fi

# FIXME: Should we detect if the MANA job was not linked with libmpistub.so
#        and point the user toward dmtcp_launch/dmtcp_restart?
#        Since mana_launch includes the MANA plugin, it's not for non-MPI jobs.
# if ldd "$target_app" | grep -q libmpistub.so; then
# fi

if [ "$verbose" == 1 ]; then
  set -x
fi

# Remove old ~/.mana_*.rc files from a week ago or more.
find $HOME/.mana*.rc -ignore_readdir_race -maxdepth 0 -mtime +7 -type f -delete

# TEMPORARY WORKAROUND:  set MPICH_SMP_SINGLE_COPY_OFF=1
#   As MANA matures, these environment variable settings will not longer
#   be needed.  Use these only if you have mysterious segfaults due
#   to corrupted memory layouts.
#     Setting this should turn of the use of /SYSV0* memory segments
#   for SysV shared memory in MPICH.  It turns out that it does not
#   stop the many /dev/xpmem memory segments from being created if/when
#   MPICH uses XPMEM.  To stop using XPMEM, set this other environment variable:
#     MPICH_SMP_SINGLE_COPY_SIZE=81920  [units of bytes]
#   This is a threshold, below which, it will _not_ create /dev/xpmem
#   for shared memory communication.  If you still see too many
#   /dev/xpmem segments, then raise the value 81920 still higher.
#   The /dev/xpmem segments are created on demand when an MPI call
#   needs to send/receive a large message.

exec env LD_LIBRARY_PATH="$libdir:$LD_LIBRARY_PATH" \
    $dir/dmtcp_launch --mpi --coord-host $submissionHost \
          --coord-port $submissionPort --no-gzip \
          --join-coordinator --disable-dl-plugin \
          --with-plugin $libdir/libmana.so $options

# srun -n1 -c1 --cpu-bind=cores bin/dmtcp_launch -i10 --mpi -h `hostname` --no-gzip --join --disable-dl-plugin --with-plugin $PWD/lib/dmtcp/libmana.so contrib/mpi-proxy-split/test/mpi_hello_world.mana.exe

# srun -n1 -c1 --cpu-bind=cores bin/mana_launch -i10 --mpi contrib/mpi-proxy-split/test/mpi_hello_world.mana.exe
